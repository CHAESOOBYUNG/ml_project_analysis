{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# features/ csv -> dataframe\n",
    "feat_cancer_raw = pd.read_csv(\"feat_cancer.csv\")\n",
    "df_cancer = pd.DataFrame(feat_cancer_raw)\n",
    "feat_old_raw = pd.read_csv(\"feat_old.csv\")\n",
    "df_old = pd.DataFrame(feat_old_raw)\n",
    "\n",
    "# target/ csv -> dataframe\n",
    "target_death_raw = pd.read_csv(\"target_death.csv\")\n",
    "df_death = pd.DataFrame(target_death_raw)\n",
    "\n",
    "# 'ADD_UP'이 포함된 데이터 제거\n",
    "df_death = df_death[~df_death['AREA'].str.contains('ADD_UP', na=False)]\n",
    "\n",
    "# 고유한 지역 리스트 추출\n",
    "areas = df_death['AREA'].unique()\n",
    "\n",
    "# feature dict / target dict\n",
    "features_dict = {}\n",
    "target_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 각 지역별 feature와 target 데이터 생성\n",
    "for area in areas:\n",
    "    area_target = df_death[df_death['AREA'] == area].drop(columns='AREA').transpose()\n",
    "    area_target.columns = ['TARGET']\n",
    "\n",
    "    # 각 feature 데이터 생성\n",
    "    area_feat_cancer = df_cancer[df_cancer['AREA'] == area].drop(columns='AREA').transpose()\n",
    "    area_feat_cancer.columns = ['CANCER']\n",
    "\n",
    "    area_feat_old = df_old[df_old['AREA'] == area].drop(columns='AREA').transpose()\n",
    "    area_feat_old.columns = ['OLD']\n",
    "\n",
    "    # 지역별 feature 데이터 결합\n",
    "    area_features = pd.concat([area_feat_cancer, area_feat_old], axis=1)\n",
    "\n",
    "    # # 'ADD_UP'이 포함된 features 데이터 제거\n",
    "    # area_features = area_features[~area_features.index.str.contains('ADD_UP', na=False)]\n",
    "\n",
    "    # dictionary에 feature와 target 저장\n",
    "    features_dict[area] = area_features\n",
    "    target_dict[area] = area_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# PolyFeatures + GridSearch + Ridge 회귀\n",
    "for area in features_dict.keys():\n",
    "    print(f\"\\n{area} 데이터에 대한 학습 시작\")\n",
    "\n",
    "    # 해당 지역의 feature와 target을 가져오기\n",
    "    X_area = features_dict[area]\n",
    "    y_area = target_dict[area]\n",
    "\n",
    "    # 데이터 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_area)\n",
    "\n",
    "    # 다항 특성 추가 (degree=2, 예시로 2차 다항식 추가)\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "    # train_test_split 80% : 20%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y_area, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Ridge 회귀 모델 + GridSearchCV\n",
    "    ridge_model = Ridge()\n",
    "    param_grid = {'alpha': np.logspace(-6, 6, 13)}  # alpha 하이퍼파라미터 튜닝\n",
    "    grid_search = GridSearchCV(ridge_model, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # 최적 모델\n",
    "    best_ridge_model = grid_search.best_estimator_\n",
    "\n",
    "    # 예측\n",
    "    y_train_pred = best_ridge_model.predict(X_train)\n",
    "    y_test_pred = best_ridge_model.predict(X_test)\n",
    "\n",
    "    # MSE (Mean Squared Error) for Test Data\n",
    "    mse = mean_squared_error(y_test, y_test_pred)\n",
    "    print(f\"{area} - 평균 제곱 오차 (MSE) for Test Data: {mse}\")\n",
    "\n",
    "    # R² for Test Data\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    print(f\"{area} - 결정 계수 (R²) for Test Data: {r2_test}\")\n",
    "\n",
    "    # MAE (Mean Absolute Error) for Test Data\n",
    "    mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    print(f\"{area} - 평균 절대 오차 (MAE) for Test Data: {mae}\")\n",
    "\n",
    "    # R² for Train Data\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f\"{area} - 결정 계수 (R²) for Train Data: {r2_train}\")\n",
    "    print(\"-\" * 50)  # 구분선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# PolyFeatures + GridSearch + Ridge 회귀\n",
    "for area in features_dict.keys():\n",
    "    print(f\"\\n{area} 데이터에 대한 학습 시작\")\n",
    "\n",
    "    # 해당 지역의 feature와 target을 가져오기\n",
    "    X_area = features_dict[area]\n",
    "    y_area = target_dict[area]\n",
    "\n",
    "    # 데이터 스케일링\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X_area)\n",
    "\n",
    "    # 다항 특성 추가 (degree=2, 예시로 2차 다항식 추가)\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "    # train_test_split 80% : 20%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y_area, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Ridge 회귀 모델 + GridSearchCV\n",
    "    ridge_model = Ridge()\n",
    "    param_grid = {'alpha': np.logspace(-6, 6, 13)}  # alpha 하이퍼파라미터 튜닝\n",
    "    grid_search = GridSearchCV(ridge_model, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # 최적 모델\n",
    "    best_ridge_model = grid_search.best_estimator_\n",
    "\n",
    "    # 예측\n",
    "    y_train_pred = best_ridge_model.predict(X_train)\n",
    "    y_test_pred = best_ridge_model.predict(X_test)\n",
    "\n",
    "    # MSE (Mean Squared Error) for Test Data\n",
    "    mse = mean_squared_error(y_test, y_test_pred)\n",
    "    print(f\"{area} - 평균 제곱 오차 (MSE) for Test Data: {mse}\")\n",
    "\n",
    "    # R² for Test Data\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    print(f\"{area} - 결정 계수 (R²) for Test Data: {r2_test}\")\n",
    "\n",
    "    # MAE (Mean Absolute Error) for Test Data\n",
    "    mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    print(f\"{area} - 평균 절대 오차 (MAE) for Test Data: {mae}\")\n",
    "\n",
    "    # R² for Train Data\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f\"{area} - 결정 계수 (R²) for Train Data: {r2_train}\")\n",
    "    print(\"-\" * 50)  # 구분선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Adjusting alpha range and reducing polynomial degree to tackle overfitting\n",
    "for area in ['SEOUL', 'JEONNAM']:\n",
    "    print(f\"\\n{area} 데이터에 대한 오버피팅 해결을 위한 학습 시작\")\n",
    "\n",
    "    # Retrieve features and target for the current area\n",
    "    X_area = features_dict[area]\n",
    "    y_area = target_dict[area]\n",
    "\n",
    "    # Data scaling using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X_area)\n",
    "\n",
    "    # Adding polynomial features (degree=1 to simplify model)\n",
    "    poly = PolynomialFeatures(degree=1)\n",
    "    X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "    # Train-test split (80% train, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y_area, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Ridge regression model with GridSearchCV for hyperparameter tuning\n",
    "    ridge_model = Ridge()\n",
    "    param_grid = {'alpha': np.logspace(-2, 3, 10)}  # Wider range for alpha\n",
    "    grid_search = GridSearchCV(ridge_model, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model from GridSearch\n",
    "    best_ridge_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = best_ridge_model.predict(X_train)\n",
    "    y_test_pred = best_ridge_model.predict(X_test)\n",
    "\n",
    "    # Metrics calculation\n",
    "    mse = mean_squared_error(y_test, y_test_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "    # Print metrics for the current area\n",
    "    print(f\"{area} - 평균 제곱 오차 (MSE) for Test Data: {mse:.4f}\")\n",
    "    print(f\"{area} - 결정 계수 (R²) for Test Data: {r2_test:.4f}\")\n",
    "    print(f\"{area} - 평균 절대 오차 (MAE) for Test Data: {mae:.4f}\")\n",
    "    print(f\"{area} - 결정 계수 (R²) for Train Data: {r2_train:.4f}\")\n",
    "    print(f\"선택된 최적 alpha: {grid_search.best_params_['alpha']}\")\n",
    "    print(\"-\" * 50)  # Separator for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Adjusting alpha range and reducing polynomial degree for all regions to tackle overfitting\n",
    "for area in features_dict.keys():\n",
    "    print(f\"\\n{area} 데이터에 대한 오버피팅 해결을 위한 학습 시작\")\n",
    "\n",
    "    # Retrieve features and target for the current area\n",
    "    X_area = features_dict[area]\n",
    "    y_area = target_dict[area]\n",
    "\n",
    "    # Data scaling using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X_area)\n",
    "\n",
    "    # Adding polynomial features (degree=1 to simplify model)\n",
    "    poly = PolynomialFeatures(degree=1)\n",
    "    X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "    # Train-test split (80% train, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y_area, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Ridge regression model with GridSearchCV for hyperparameter tuning\n",
    "    ridge_model = Ridge()\n",
    "    param_grid = {'alpha': np.logspace(-2, 3, 10)}  # Wider range for alpha\n",
    "    grid_search = GridSearchCV(ridge_model, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model from GridSearch\n",
    "    best_ridge_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = best_ridge_model.predict(X_train)\n",
    "    y_test_pred = best_ridge_model.predict(X_test)\n",
    "\n",
    "    # Metrics calculation\n",
    "    mse = mean_squared_error(y_test, y_test_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "    # Print metrics for the current area\n",
    "    print(f\"{area} - 평균 제곱 오차 (MSE) for Test Data: {mse:.4f}\")\n",
    "    print(f\"{area} - 결정 계수 (R²) for Test Data: {r2_test:.4f}\")\n",
    "    print(f\"{area} - 평균 절대 오차 (MAE) for Test Data: {mae:.4f}\")\n",
    "    print(f\"{area} - 결정 계수 (R²) for Train Data: {r2_train:.4f}\")\n",
    "    print(f\"선택된 최적 alpha: {grid_search.best_params_['alpha']}\")\n",
    "    print(\"-\" * 50)  # Separator for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Re-analyzing with MinMaxScaler, PolynomialFeatures(degree=2), and CV=7 for Ridge regression\n",
    "for area in features_dict.keys():\n",
    "    print(f\"\\n{area} 데이터에 대한 학습 시작 (MinMaxScaler, PolynomialFeatures(degree=2), CV=7)\")\n",
    "\n",
    "    # Retrieve features and target for the current area\n",
    "    X_area = features_dict[area]\n",
    "    y_area = target_dict[area]\n",
    "\n",
    "    # Data scaling using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X_area)\n",
    "\n",
    "    # Adding polynomial features (degree=2 for interaction terms)\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "    # Train-test split (80% train, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y_area, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Ridge regression model with GridSearchCV for hyperparameter tuning\n",
    "    ridge_model = Ridge()\n",
    "    param_grid = {'alpha': np.logspace(-6, 6, 13)}  # Alpha hyperparameter tuning\n",
    "    grid_search = GridSearchCV(ridge_model, param_grid, cv=7)  # Using 7-fold cross-validation\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model from GridSearch\n",
    "    best_ridge_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = best_ridge_model.predict(X_train)\n",
    "    y_test_pred = best_ridge_model.predict(X_test)\n",
    "\n",
    "    # Metrics calculation\n",
    "    mse = mean_squared_error(y_test, y_test_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "    # Print metrics for the current area\n",
    "    print(f\"{area} - 평균 제곱 오차 (MSE) for Test Data: {mse:.4f}\")\n",
    "    print(f\"{area} - 결정 계수 (R²) for Test Data: {r2_test:.4f}\")\n",
    "    print(f\"{area} - 평균 절대 오차 (MAE) for Test Data: {mae:.4f}\")\n",
    "    print(f\"{area} - 결정 계수 (R²) for Train Data: {r2_train:.4f}\")\n",
    "    print(f\"선택된 최적 alpha: {grid_search.best_params_['alpha']}\")\n",
    "    print(\"-\" * 50)  # Separator for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
